{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7fc690-7fa6-4219-b9a6-43ee71da0534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pydicom\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve, matthews_corrcoef, auc, accuracy_score, recall_score, precision_score, f1_score\n",
    "import torchvision\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from torchvision import transforms, datasets, models\n",
    "import torch\n",
    "from torch import optim, cuda\n",
    "from torch.utils.data import DataLoader, sampler\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "from timeit import default_timer as timer\n",
    "from collections import OrderedDict\n",
    "\n",
    "import timm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d46293e-0f0d-4bcc-a1c1-489c5994d8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7825b77b-85bd-43e8-9b37-f36b78d085d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.LOAD_TRUNCATED_IMAGES = True\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2247eff4-de50-40f5-a5cd-b79eec520570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fce057c-bd36-4944-b11b-8b96cdfa6ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('image_table.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4fe3d1-8960-4527-b3bf-710caae9e27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgtransResize = (320, 320)\n",
    "#TRANSFORM DATA\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "transformList = []\n",
    "transformList.append(transforms.RandomHorizontalFlip())\n",
    "transformList.append(transforms.RandomInvert())\n",
    "transformList.append(transforms.RandomRotation(degrees=(-15, 15), expand=False, interpolation=InterpolationMode.BICUBIC))\n",
    "#transformList.append(transforms.ColorJitter(brightness=0.5, contrast=0.5)) # try 0.75 next\n",
    "#transformList.append(transforms.RandAugment(num_ops=2, magnitude=9, interpolation=InterpolationMode.BICUBIC))\n",
    "transformList.append(transforms.Resize(imgtransResize,interpolation=InterpolationMode.BICUBIC))\n",
    "transformList.append(transforms.ToTensor())\n",
    "transformList.append(normalize)      \n",
    "transformSequence=transforms.Compose(transformList)\n",
    "\n",
    "\n",
    "val_transformList = []\n",
    "val_transformList.append(transforms.Resize(imgtransResize,interpolation=InterpolationMode.BICUBIC))\n",
    "val_transformList.append(transforms.ToTensor())\n",
    "val_transformList.append(normalize)\n",
    "val_transformSequence=transforms.Compose(val_transformList)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32d21c3-d26e-40ac-9d31-c5f543718ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class png_loader(Dataset):\n",
    "    def __init__(self, image_list_file, transform=None):\n",
    "\n",
    "        image_names = []\n",
    "        labels = []\n",
    "\n",
    "        for row, line in image_list_file.iterrows():\n",
    "            image_name = line['png_path']\n",
    "            label = line[y_list]\n",
    "            \n",
    "            for i in range(len(label)):\n",
    "                label[i] = line[y_list[i]]\n",
    "            \n",
    "            image_names.append(image_name)\n",
    "            labels.append(label)\n",
    "\n",
    "        self.image_names = image_names\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Take the index of item and returns the image and its labels\"\"\"\n",
    "        \n",
    "        filename = self.image_names[index]\n",
    "\n",
    "        image = Image.open(root_dir + str(filename))\n",
    "        \n",
    "        image = image.convert('RGB')\n",
    "\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.FloatTensor(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d902e6c-aa79-425a-9d44-e5a7a6d259c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_list = ['bad_exam']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc821ae0-d85c-42a0-b6a5-4f45d95a0251",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_BatchSize = 8\n",
    "nnClassCount = len(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c23c7c-e82c-4615-a66b-d111e888702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "empi_list = data_df.empi_anon.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca54c363-2a0e-4de9-8c91-939ea7d2f848",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_list = shuffle(empi_list, random_state=42)[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52ad1f7-f6d6-49c6-828a-513b218575f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data_df[~data_df.empi_anon.isin(val_list)]\n",
    "validate_df = data_df[data_df.empi_anon.isin(val_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a754a6-5075-48fe-9e40-2ee1434f2f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTrain = png_loader(train_df, transformSequence)\n",
    "datasetValid = png_loader(validate_df, val_transformSequence)\n",
    "\n",
    "dataLoaderTrain = DataLoader(dataset=datasetTrain, batch_size=training_BatchSize, shuffle=True,  num_workers=32, pin_memory=True, drop_last=True)\n",
    "dataLoaderVal = DataLoader(dataset=datasetValid, batch_size=training_BatchSize, shuffle=False, num_workers=32, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c593219-1a5b-4216-88f3-dc37f054a371",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_Trainer():\n",
    "\n",
    "    def train (model, dataLoaderTrain, dataLoaderVal, nnClassCount, trMaxEpoch, launchTimestamp, checkpoint):\n",
    "        \n",
    "        overall_start = timer()\n",
    "        #SETTINGS: OPTIMIZER & SCHEDULER\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=0, min_lr=1e-6, verbose=True)\n",
    "        #SETTINGS: LOSS\n",
    "        loss = torch.nn.BCEWithLogitsLoss()\n",
    "        #loss = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        #LOAD CHECKPOINT \n",
    "        if checkpoint != None and use_gpu:\n",
    "            modelCheckpoint = torch.load(checkpoint)\n",
    "            model.load_state_dict(modelCheckpoint['state_dict'])\n",
    "            optimizer.load_state_dict(modelCheckpoint['optimizer'])\n",
    "\n",
    "        \n",
    "        #TRAIN THE NETWORK\n",
    "        lossMIN = 100000\n",
    "        start = timer()\n",
    "        dir_path = dir_str+launchTimestamp\n",
    "        #os.mkdir(dir_path)\n",
    "        for epochID in range(0, trMaxEpoch):\n",
    "            \n",
    "            timestampTime = time.strftime(\"%H%M%S\")\n",
    "            timestampDate = time.strftime(\"%d%m%Y\")\n",
    "            timestampSTART = timestampDate + '-' + timestampTime\n",
    "            \n",
    "            batchs, losst = Model_Trainer.epochTrain(model, dataLoaderTrain, optimizer, trMaxEpoch, epochID, nnClassCount, loss, start, lossMIN, launchTimestamp, dir_path)\n",
    "            outLoss, ground_truth, prediction, aurocMean, aurocIndividual = Model_Trainer.test(model, dataLoaderVal, nnClassCount, class_names, loss)\n",
    "   \n",
    "            outLoss = outLoss.cpu().detach().numpy()\n",
    "            print(\"\\nval loss: \" + str(outLoss))\n",
    "\n",
    "            timestampTime = time.strftime(\"%H%M%S\")\n",
    "            timestampDate = time.strftime(\"%d%m%Y\")\n",
    "            timestampEND = timestampDate + '-' + timestampTime\n",
    "            scheduler.step(outLoss)\n",
    "            \n",
    "            torch.save({'epoch': epochID + 1, 'state_dict': model.state_dict(), 'optimizer' : optimizer.state_dict()}, 'save_bad_exam_models/bad_exam_detection_' + timestampEND + '_val_loss-' + str(outLoss) + '.pth.tar')   \n",
    "   \n",
    "        return batchs, losst        \n",
    "    #-------------------------------------------------------------------------------- \n",
    "       \n",
    "    def epochTrain(model, dataLoader, optimizer, epochMax, epochID, classCount, loss, start, lossMIN, launchTimestamp, dir_path):\n",
    "        \n",
    "        batch = []\n",
    "        losstrain = []\n",
    "        losseval = []\n",
    "        \n",
    "        \n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        for batchID, (varInput, target) in enumerate(dataLoaderTrain):\n",
    "            \n",
    "            target = torch.squeeze(target)\n",
    "            target = torch.ravel(target)\n",
    "            varInput = varInput.cuda()\n",
    "            varTarget = target.cuda(non_blocking = True)\n",
    "            \n",
    "            with torch.cuda.amp.autocast():\n",
    "                varOutput = model(varInput)\n",
    "                varOutput = np.squeeze(varOutput)\n",
    "                lossvalue = loss(varOutput, varTarget)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(lossvalue).backward()#lossvalue.backward()\n",
    "            scaler.step(optimizer)#optimizer.step()\n",
    "            scaler.update()\n",
    "          \n",
    "            l = lossvalue.item()\n",
    "            losstrain.append(l)\n",
    "            print(\n",
    "                f'Epoch: {epochID}\\t{100 * (batchID / (len(datasetTrain)//training_BatchSize)):.1f}% complete. {timer() - start:.1f} seconds elapsed in epoch. Training loss: ' + str(round(np.mean(losstrain), 4)),\n",
    "                end='\\r')\n",
    "           \n",
    "        return batch, losstrain\n",
    "    \n",
    "    \n",
    "    def epochVal(model, dataLoader, optimizer, loss):\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        lossVal = 0 \n",
    "        lossValNorm = 0\n",
    "        \n",
    "        outGT = torch.FloatTensor().cuda()\n",
    "        outPRED = torch.FloatTensor().cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (varInput, target) in enumerate(dataLoader):\n",
    "                \n",
    "                \n",
    "                target = torch.FloatTensor(target)\n",
    "                target = target.cuda(non_blocking = True)\n",
    "                \n",
    "                varOutput = model(varInput)\n",
    "                \n",
    "                losstensor = loss(varOutput, target)\n",
    "                \n",
    "                lossVal += losstensor\n",
    "                lossValNorm += 1\n",
    "                                \n",
    "                outGT = torch.cat((outGT, target), 0).cuda()\n",
    "                outPRED = torch.cat((outPRED, varOutput), 0)\n",
    "                \n",
    "                print(\n",
    "                    f'Epoch: {epochID}\\t{100 * (batchID / (len(dataLoader)//training_BatchSize)):.1f}% complete. {timer() - start:.1f} seconds elapsed in epoch. Training loss: ' + str(round(np.mean(losstrain), 4)),\n",
    "                    end='\\r')\n",
    "           \n",
    "        \n",
    "                \n",
    "        \n",
    "        outLoss = lossVal / lossValNorm\n",
    "        \n",
    "        print(\"val_loss: \" + str(outLoss))\n",
    "           \n",
    "        return outLoss, outGT, outPRED\n",
    "    \n",
    "\n",
    "    \n",
    "    def computeAUROC (dataGT, dataPRED, classCount):\n",
    "        \n",
    "        outAUROC = []\n",
    "        \n",
    "        datanpGT = dataGT.cpu().numpy()\n",
    "        datanpPRED = dataPRED.cpu().numpy()\n",
    "\n",
    "        outAUROC.append(roc_auc_score(datanpGT, datanpPRED))\n",
    "\n",
    "        return outAUROC\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def test(model, dataLoaderTest, nnClassCount, class_names, loss):   \n",
    "        \n",
    "        outGT = torch.FloatTensor().cuda()\n",
    "        outPRED = torch.FloatTensor().cuda()\n",
    "\n",
    "       \n",
    "        model.eval()\n",
    "        \n",
    "        lossVal = 0\n",
    "        lossValNorm = 0\n",
    "        \n",
    "        batch_num = 0\n",
    "        div = len(dataLoaderTest)\n",
    "        with torch.no_grad():\n",
    "            for i, (input, target) in enumerate(dataLoaderTest):\n",
    "                \n",
    "                target = torch.squeeze(target)\n",
    "                target = torch.ravel(target)\n",
    "                target = target.cuda()\n",
    "                outGT = torch.cat((outGT, target), 0).cuda()\n",
    "\n",
    "                bs, c, h, w = input.size()\n",
    "                varInput = input.view(-1, c, h, w)\n",
    "            \n",
    "                with torch.cuda.amp.autocast():\n",
    "                    varOutput = model(varInput)\n",
    "                    varOutput = np.squeeze(varOutput)\n",
    "                    losstensor = loss(varOutput, target)   \n",
    "                                \n",
    "                lossVal += losstensor\n",
    "                lossValNorm += 1\n",
    "                \n",
    "                outPRED = torch.cat((outPRED, varOutput), 0)\n",
    "                \n",
    "                print(\n",
    "                    str(round(batch_num/div,3)),\n",
    "                    end='\\r')\n",
    "               \n",
    "                batch_num = batch_num + 1\n",
    "                \n",
    "                \n",
    "        outLoss = lossVal / lossValNorm \n",
    "        \n",
    "        aurocIndividual = Model_Trainer.computeAUROC(outGT, outPRED, nnClassCount)\n",
    "        aurocMean = np.array(aurocIndividual).mean()\n",
    "        \n",
    "        print ('\\nAUROC mean ', round(aurocMean, 5))\n",
    "        \n",
    "        for i in range (0, len(aurocIndividual)):\n",
    "            print (class_names[i], ' ', round(aurocIndividual[i],5))\n",
    "            \n",
    "        print(\"\\n\")\n",
    "        \n",
    "        return outLoss, outGT, outPRED, aurocMean, aurocIndividual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1f9688-a03d-40b4-9453-aa219dec61a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_320', pretrained=True, in_chans=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bf3631-d67f-4499-a70a-5362561bdc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = model.head.fc.in_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a53712-2399-4cbc-92f0-9595b0ff3945",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.head.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, len(y_list), bias=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811da3be-f843-4b7a-bd41-63a7e0f573b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.DataParallel(model).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf5cef8-e3af-4395-8094-8d3421ffc41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnClassCount = len(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eebf9f-0625-4b5e-a617-72d45f4dfa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "timestampTime = time.strftime(\"%H%M%S\")\n",
    "timestampDate = time.strftime(\"%d%m%Y\")\n",
    "timestampLaunch = timestampDate + '-' + timestampTime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103e077a-8903-46d2-8dfc-0c0cef4a224c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_str = 'bad_exams'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10528f7f-e50e-4a6a-882d-d66fb3358fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, losst = Model_Trainer.train(model, dataLoaderTrain, dataLoaderVal, nnClassCount, trMaxEpoch, timestampLaunch, checkpoint = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7934de9-8f6d-4848-b203-49b54c583cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0553f6d7-f16f-4e67-a32f-f7ac194f3d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
